import numpy as np

class Neuronio:
    """
    Um neur√¥nio artificial b√°sico que simula o comportamento de um neur√¥nio biol√≥gico.
    Recebe m√∫ltiplas entradas, aplica pesos, soma tudo e passa por uma fun√ß√£o de ativa√ß√£o.
    """
    
    def __init__(self, n_entradas):
        """
        Inicializa o neur√¥nio com pesos aleat√≥rios.
        
        Exemplo: Neuronio(2) cria um neur√¥nio que aceita 2 entradas
        - self.pesos = [-0.05, 0.12]  (valores aleat√≥rios pequenos)
        - self.bias = 0.0             (ajuste independente)
        """
        # Pesos aleat√≥rios pequenos + bias
        self.pesos = np.random.normal(0, 0.1, n_entradas)
        self.bias = 0.0
    
    def step_function(self, z):
        """
        Fun√ß√£o de ativa√ß√£o degrau (step function) - PERCEPTRON CL√ÅSSICO
        
        Exemplos:
        - step_function(-2) = 0  (qualquer valor negativo = 0)
        - step_function(0)  = 1  (zero ou positivo = 1)
        - step_function(5)  = 1  (qualquer valor positivo = 1)
        
        √â como um "interruptor digital": ou dispara (1) ou n√£o dispara (0).
        N√£o h√° meio termo como no sigmoid!
        """
        return 1 if z >= 0 else 0
    
    def forward(self, entradas):
        """
        Propaga√ß√£o para frente: calcula a sa√≠da do neur√¥nio.
        
        Passos:
        1. Soma ponderada: z = entrada1*peso1 + entrada2*peso2 + bias
        2. Ativa√ß√£o: sa√≠da = step_function(z) -> 0 ou 1
        
        Exemplo com entradas=[1, 0], pesos=[0.5, -0.3], bias=0.1:
        - z = 1*0.5 + 0*(-0.3) + 0.1 = 0.6
        - sa√≠da = step_function(0.6) = 1 (porque 0.6 >= 0)
        """
        # Converte para array NumPy se necess√°rio
        entradas = np.array(entradas)
        # Soma ponderada + ativa√ß√£o
        z = np.dot(entradas, self.pesos) + self.bias
        return self.step_function(z)
    
    def treinar(self, entradas, target, lr=0.5):
        """
        Treina o neur√¥nio ajustando pesos baseado no erro - REGRA DO PERCEPTRON
        
        Algoritmo (Perceptron Learning Rule):
        1. Faz predi√ß√£o (0 ou 1)
        2. Calcula erro = target - predi√ß√£o  
        3. Se erro != 0, ajusta pesos
        4. Novo_peso = peso_atual + lr * erro * entrada
        
        Exemplo: target=1, predi√ß√£o=0, entrada=[1,0]
        - erro = 1 - 0 = 1 (erro positivo)
        - peso1 += 0.5 * 1 * 1 = +0.5 (aumenta peso da entrada ativa)
        - peso2 += 0.5 * 1 * 0 = 0 (n√£o muda peso da entrada inativa)
        """
        # Converte para array NumPy
        entradas = np.array(entradas)
        
        # Predi√ß√£o
        predicao = self.forward(entradas)
        
        # Erro (s√≥ pode ser -1, 0 ou +1)
        erro = target - predicao
        
        # Atualiza pesos APENAS se houver erro (regra cl√°ssica do perceptron)
        if erro != 0:
            self.pesos += lr * erro * entradas
            self.bias += lr * erro
        
        return erro

# Exemplo: Neur√¥nio aprendendo fun√ß√£o AND
if __name__ == "__main__":
    """
    Demonstra√ß√£o: ensina um perceptron a simular porta l√≥gica AND
    
    Fun√ß√£o AND:
    - 0 AND 0 = 0 (falso E falso = falso)
    - 0 AND 1 = 0 (falso E verdadeiro = falso)  
    - 1 AND 0 = 0 (verdadeiro E falso = falso)
    - 1 AND 1 = 1 (verdadeiro E verdadeiro = verdadeiro)
    
    O perceptron vai aprender automaticamente os pesos corretos!
    Diferen√ßa: sa√≠da ser√° exatamente 0 ou 1 (n√£o probabilidades)
    """
    # Cria neur√¥nio com 2 entradas
    neuronio = Neuronio(2)
    
    # Dados: fun√ß√£o AND
    X = [[0,0], [0,1], [1,0], [1,1]]
    y = [0, 0, 0, 1]
    
    print("üß† Treinando PERCEPTRON para fun√ß√£o AND...")
    
    # Treina at√© convergir (ou m√°ximo 1000 √©pocas)
    for epoca in range(1000):
        erro_total = 0
        for i in range(4):
            erro = neuronio.treinar(X[i], y[i])
            erro_total += abs(erro)
        
        # Se n√£o h√° mais erros, convergiu!
        if erro_total == 0:
            print(f"‚úÖ Convergiu na √©poca {epoca + 1}!")
            break
    
    # Testa
    print("\nüìä Resultados:")
    for i in range(4):
        resultado = neuronio.forward(X[i])
        print(f"{X[i][0]} AND {X[i][1]} = {resultado} ({'‚úÖ' if resultado == y[i] else '‚ùå'})")
    
    print(f"\n‚öôÔ∏è Pesos: {neuronio.pesos}")
    print(f"‚öôÔ∏è Bias: {neuronio.bias:.3f}")
    
    print(f"\nüí° PERCEPTRON vs NEUR√îNIO MODERNO:")
    print(f"‚Ä¢ Perceptron: sa√≠da bin√°ria (0 ou 1)")
    print(f"‚Ä¢ Neur√¥nio moderno: sa√≠da probabil√≠stica (0.0 a 1.0)")
    print(f"‚Ä¢ Perceptron: fun√ß√£o degrau")
    print(f"‚Ä¢ Neur√¥nio moderno: fun√ß√£o sigmoid/relu/etc")